{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255 #Нормирование изображения\n",
    "x_test = x_test / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.reshape(tf.cast(x_train, tf.float32),[-1,28*28])\n",
    "x_text = tf.reshape(tf.cast(x_test, tf.float32),[-1,28*28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 784)\n",
      "Y_train: (60000, 10)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' + str(x_train.shape))\n",
    "print('Y_train: ' + str(y_train.shape))\n",
    "print('X_test:  '  + str(x_test.shape))\n",
    "print('Y_test:  '  + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNN(tf.Module): #Это слой\n",
    "    def __init__(self, outputs, activate=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.outputs = outputs\n",
    "        self.activate = activate\n",
    "        self.fl_init = False\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.fl_init:\n",
    "            self.w = tf.random.truncated_normal((x.shape[-1], self.outputs), stddev=0.1, name=\"w\")\n",
    "            self.b = tf.zeros([self.outputs], dtype=tf.float32, name=\"b\")\n",
    "            \n",
    "        y = x @ self.w + self.b\n",
    "\n",
    "        if self.activate == \"relu\":\n",
    "            return tf.nn.relu(y) #\n",
    "        elif self.activate == \"softmax\":\n",
    "            return tf.nn.softmax(y) #\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = DenseNN(128)\n",
    "layer_2 = DenseNN(10, activate=\"softmax\")\n",
    "\n",
    "def model_predict(x):\n",
    "    y = layer_1(x)\n",
    "    y = layer_2(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = lambda y_true, y_pred: tf.reduce_mean(tf.losses.categorical_crossentropy(y_true, y_pred))\n",
    "opt = tf.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "EPOCHS = 10  #КОл-во эпох\n",
    "TOTAL = x_train.shape[0] #Размер обучающей выборки\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4595.923\n",
      "4594.116\n",
      "4607.0\n"
     ]
    }
   ],
   "source": [
    "#ЦИкл обучения\n",
    "for n in range(EPOCHS): \n",
    "    loss = 0\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            f_loss = cross_entropy(y_batch, model_predict(x_batch))\n",
    "\n",
    "        loss += f_loss\n",
    "        grads = tape.gradient(f_loss,[layer_1.trainable_variables,layer_2.trainable_variables])\n",
    "        opt.apply_gradients(zip(grads[0], layer_1.trainable_variables))\n",
    "        opt.apply_gradients(zip(grads[1], layer_1.trainable_variables))\n",
    "\n",
    "    print(loss.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\AppData\\Local\\Temp\\ipykernel_9432\\706371978.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  acc = len(y_test[y_test== y2])/y_test.shape[0] * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (10000,) and (10000, 10) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[179], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(acc)\n\u001b[0;32m      6\u001b[0m acc \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mAccuracy()\n\u001b[1;32m----> 7\u001b[0m acc\u001b[39m.\u001b[39;49mupdate_state(y_test, y2)\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(acc\u001b[39m.\u001b[39mresult(),numpy()\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\metrics_utils.py:77\u001b[0m, in \u001b[0;36mupdate_state_wrapper.<locals>.decorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTrying to run metric.update_state in replica context when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe metric was not created in TPUStrategy scope. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMake sure the keras Metric is created in TPUstrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mscope. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     76\u001b[0m \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 77\u001b[0m     update_op \u001b[39m=\u001b[39m update_state_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39mif\u001b[39;00m update_op \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# update_op will be None in eager execution.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     metric_obj\u001b[39m.\u001b[39madd_update(update_op)\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\base_metric.py:140\u001b[0m, in \u001b[0;36mMetric.__new__.<locals>.update_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m control_status \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    137\u001b[0m ag_update_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    138\u001b[0m     obj_update_state, control_status\n\u001b[0;32m    139\u001b[0m )\n\u001b[1;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m ag_update_state(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\base_metric.py:691\u001b[0m, in \u001b[0;36mMeanMetricWrapper.update_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    684\u001b[0m y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[0;32m    685\u001b[0m     y_pred, y_true\n\u001b[0;32m    686\u001b[0m )\n\u001b[0;32m    688\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    689\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    690\u001b[0m )\n\u001b[1;32m--> 691\u001b[0m matches \u001b[39m=\u001b[39m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fn_kwargs)\n\u001b[0;32m    692\u001b[0m mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(matches)\n\u001b[0;32m    693\u001b[0m sample_weight \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mapply_valid_mask(\n\u001b[0;32m    694\u001b[0m     matches, sample_weight, mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction\n\u001b[0;32m    695\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\accuracy_metrics.py:361\u001b[0m, in \u001b[0;36maccuracy\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maccuracy\u001b[39m(y_true, y_pred):\n\u001b[0;32m    355\u001b[0m     [\n\u001b[0;32m    356\u001b[0m         y_pred,\n\u001b[0;32m    357\u001b[0m         y_true,\n\u001b[0;32m    358\u001b[0m     ], _ \u001b[39m=\u001b[39m metrics_utils\u001b[39m.\u001b[39mragged_assert_compatible_and_get_flat_values(\n\u001b[0;32m    359\u001b[0m         [y_pred, y_true]\n\u001b[0;32m    360\u001b[0m     )\n\u001b[1;32m--> 361\u001b[0m     y_true\u001b[39m.\u001b[39;49mshape\u001b[39m.\u001b[39;49massert_is_compatible_with(y_pred\u001b[39m.\u001b[39;49mshape)\n\u001b[0;32m    362\u001b[0m     \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m y_pred\u001b[39m.\u001b[39mdtype:\n\u001b[0;32m    363\u001b[0m         y_pred \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(y_pred, y_true\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\mihee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1359\u001b[0m, in \u001b[0;36mTensorShape.assert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Raises exception if `self` and `other` do not represent the same shape.\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m \n\u001b[0;32m   1349\u001b[0m \u001b[39mThis method can be used to assert that there exists a shape that both\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[39m  ValueError: If `self` and `other` do not represent the same shape.\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_compatible_with(other):\n\u001b[1;32m-> 1359\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mShapes \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m are incompatible\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m, other))\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (10000,) and (10000, 10) are incompatible"
     ]
    }
   ],
   "source": [
    "y = model_predict(x_test)\n",
    "y2 = tf.argmax(y, axis=1).numpy()\n",
    "acc = len(y_test[y_test== y2])/y_test.shape[0] * 100\n",
    "print(acc)\n",
    "\n",
    "acc = tf.metrics.Accuracy()\n",
    "acc.update_state(y_test, y2)\n",
    "print(acc.result().numpy()*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
