{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 13:36:30.756438: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    def predprocess_image(image,label):\n",
    "        image = tf.image.convert_image_dtype(image,tf.float32)\n",
    "        return image, label\n",
    "    ds_train, info = tfds.load(\"cifar10\",with_info=True, split=\"train\",as_supervised=True)\n",
    "    ds_test = tfds.load(\"cifar10\",split=\"test\",as_supervised=True)\n",
    "\n",
    "    ds_train = ds_train.repeat().shuffle(1024).map(predprocess_image).batch(batch_size)\n",
    "\n",
    "    ds_test = ds_test.repeat().shuffle(1024).map(predprocess_image).batch(batch_size)\n",
    "\n",
    "    return ds_train, ds_test, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3),padding=\"same\", input_shape=input_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\")) #Sigmoid, Tanh, ReLU\n",
    "    model.add(Dropout(0.5)) #Регуляция\n",
    "    model.add(Dense(num_classes,activation=\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     ds_train, ds_test,info\u001b[39m=\u001b[39mload_data()\n\u001b[1;32m      3\u001b[0m     model \u001b[39m=\u001b[39m create_model(input_shape\u001b[39m=\u001b[39minfo\u001b[39m.\u001b[39mfeatures[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m     logdir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcifar10-model-v1\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mconvert_image_dtype(image,tf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m image, label\n\u001b[0;32m----> 6\u001b[0m ds_train, info \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mcifar10\u001b[39m\u001b[39m\"\u001b[39m,with_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,as_supervised\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m ds_test \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mcifar10\u001b[39m\u001b[39m\"\u001b[39m,split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m,as_supervised\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m ds_train \u001b[39m=\u001b[39m ds_train\u001b[39m.\u001b[39mrepeat()\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mmap(predprocess_image)\u001b[39m.\u001b[39mbatch(batch_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ds_train, ds_test,info=load_data()\n",
    "    model = create_model(input_shape=info.features[\"image\"].shape)\n",
    "\n",
    " \n",
    "\n",
    "    logdir = os.path.join(\"logs\", \"cifar10-model-v1\")\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=logdir)\n",
    "    if not os.path.isdir(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    "\n",
    "    model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=1, \n",
    "              steps_per_epoch=info.splits[\"train\"].num_examples // batch_size,\n",
    "              validation_steps=info.splits[\"test\"].num_examples // batch_size,\n",
    "              callbacks = [tensorboard])\n",
    "    \n",
    "    model.save(\"results/cifar10-model-v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test, info = load_data()\n",
    "\n",
    "model = load_model(\"results/cifar10-model-v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss, accuracy = model.evaluate(, y_test)\n",
    "#print(\"Test accuracy:\",accuracy*100,\"%\")\n",
    "\n",
    "\n",
    "data_sample = next(iter(ds_test))\n",
    "sample_image = data_sample[0].numpy()[0]\n",
    "sample_label = categories[data_sample[1].numpy()[0]]\n",
    "prediction = np.argmax(model.predict(sample_image.reshape(-1, *sample_image.shape))[0])\n",
    "\n",
    "print(\"Predicted label:\",categories[prediction])\n",
    "print(\"True label:\", sample_label)\n",
    "\n",
    "# Display the sample image\n",
    "plt.imshow(sample_image)\n",
    "plt.show()\n",
    "print(sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# загрузить изображение\n",
    "image = Image.open(\"dog.jpg\")\n",
    "\n",
    "# изменить размер изображения\n",
    "image = image.resize((32, 32))\n",
    "\n",
    "# преобразовать изображение в массив numpy\n",
    "image_array = np.array(image)\n",
    "\n",
    "# выполнить нормализацию значений пикселей\n",
    "normalized_image_array = (image_array.astype(np.float32) / 255.0 - 0.5) / 0.5\n",
    "\n",
    "# добавить измерение пакета к массиву\n",
    "processed_image = np.expand_dims(normalized_image_array, axis=0)\n",
    "processed_image = np.squeeze(processed_image)\n",
    "prediction = np.argmax(model.predict(processed_image.reshape(-1, *processed_image.shape))[0])\n",
    "\n",
    "# вывести результат\n",
    "print(\"Predicted label:\", categories[prediction])\n",
    "\n",
    "plt.imshow(processed_image)\n",
    "plt.show()\n",
    "print(processed_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# загрузить изображение\n",
    "image = Image.open(\"cat.jpg\")\n",
    "\n",
    "# изменить размер изображения\n",
    "image = image.resize((32, 32))\n",
    "\n",
    "# преобразовать изображение в массив numpy\n",
    "image_array = np.array(image)\n",
    "\n",
    "# выполнить нормализацию значений пикселей\n",
    "normalized_image_array = (image_array.astype(np.float32) / 255.0 - 0.5) / 0.5\n",
    "\n",
    "# добавить измерение пакета к массиву\n",
    "processed_image = np.expand_dims(normalized_image_array, axis=0)\n",
    "processed_image = np.squeeze(processed_image)\n",
    "\n",
    "plt.imshow(processed_image)\n",
    "plt.show()\n",
    "print(processed_image.shape)\n",
    "\n",
    "prediction = np.argmax(model.predict(processed_image.reshape(-1, *processed_image.shape))[0])\n",
    "\n",
    "# вывести результат\n",
    "print(\"Predicted label:\", categories[prediction])\n",
    "\n",
    "\n",
    "# преобразовать изображение в массив numpy\n",
    "image_array = np.array(image)\n",
    "\n",
    "# выполнить нормализацию значений пикселей\n",
    "normalized_image_array = (image_array.astype(np.float32) / 255.0 - 0.5) / 0.5\n",
    "\n",
    "# добавить измерение пакета к массиву\n",
    "processed_image = np.expand_dims(normalized_image_array, axis=0)\n",
    "\n",
    "# выполнить предсказание на обработанном изображении\n",
    "prediction = model.predict(processed_image)\n",
    "\n",
    "# вывести вероятности для каждого класса\n",
    "for i, proba in enumerate(prediction[0]):\n",
    "    print(f\"{categories[i]}: {proba}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Существует множество причин, почему обученная нейронная сеть может плохо классифицировать изображения. Ниже перечислены некоторые из наиболее распространенных проблем:\n",
    "Недостаточность объема данных для обучения. Чтобы обучить нейронную сеть на задачу классификации изображений, нужно иметь большой и разнообразный набор данных. Если количество обучающих примеров недостаточно, то сеть может не научиться распознавать изображения на новых данных.\n",
    "Недостаточная глубина сети. Если сеть слишком мала, она может не быть способна выделять достаточно сложные признаки изображения, чтобы классифицировать его правильно.\n",
    "Неправильный выбор архитектуры сети. Различные архитектуры сетей лучше подходят для разных задач классификации изображений. Например, для классификации изображений лиц лучше использовать сверточные нейронные сети, а для классификации изображений цифр лучше использовать полносвязные нейронные сети.\n",
    "Неправильное предобработка изображений. Изображения должны быть предобработаны перед подачей их на вход сети. Если этот процесс неправильно выполнен, то сеть может получить неправильную информацию о изображении.\n",
    "Ошибки в процессе обучения. Обучение нейронной сети может быть неправильно настроено или неоптимальным. Например, сеть может быть переобученной на обучающем наборе, что приведет к плохой обобщающей способности на новых данных.\n",
    "Недостаточное количество эпох обучения. Если обучение сети было недостаточно продолжительным, то сеть может не успеть усвоить достаточное количество информации для классификации изображений.\n",
    "Неправильно обработаны данные для анализа нейронной сетью, так например в примере нейронная сеть выдавала ошибку при распознании лошади, по ее мнению это был аэроплан. Данная ошибка вознилка потому что изображение было не информативным, а именно не контрасным. Смотря на очетания изображение которое имело разрешение 32 на 32 пикселя, на изображении плохо видно было лошадь, хорошо видно было очернания неба и земли, поэтому нейросеть допустила ошибку\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
